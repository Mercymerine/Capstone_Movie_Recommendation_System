{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGFTC11oIjtk4tp4iemR14",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mercymerine/Capstone_Movie_Recommendation_System/blob/main/main_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install feedparser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyE77B87QqzK",
        "outputId": "001f44f3-4c50-4cfc-d089-dfceadf3ff28"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting sgmllib3k (from feedparser)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=9709d7ee0252bdab08dc3834565e67fee9fe100b969fc0b09c7b164ca4bf4128\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser\n",
            "Successfully installed feedparser-6.0.11 sgmllib3k-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install schedule"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94RhFPYwQ6ZZ",
        "outputId": "38f726bc-269f-4807-935e-eab8e880b029"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting schedule\n",
            "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "cDTtwgcGOWHx",
        "outputId": "6302c829-63d5-4d77-a91e-1fc153fab913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RSS feed fetched and written to CSV at 2024-10-10 16:40:19\n",
            "Link: https://abcnews.go.com/US/video/clearwater-fl-mayor-latest-concerns-amidst-hurricane-milton-114670000, Title: video clearwater fl mayor late concern amidst hurricane milton abc news linsey davis speak clearwater mayor bruce rector unpack big concern milton make landfall immediate step storm condition slow, Author: ABC News\n",
            "Link: https://www.cnn.com/2024/10/10/politics/ethel-kennedy-dies/index.html, Title: ethel kennedy human right activist widow robert f. kennedy die 96 ethel kennedy widow robert f. kennedy die family announce thursday 96, Author: Karl de Vries\n",
            "Link: https://www.miamiherald.com/news/local/environment/article293766234.html, Title: tornado major milton threat florida kill 4 destroy home nws miami send record number tornado warning ahead hurricane milton, Author: Alex Harris\n",
            "Link: https://www.washingtonpost.com/obituaries/2024/10/10/rfk-widow-ethel-kennedy-dies/, Title: ethel kennedy widow robert kennedy family matriarch die 96 scarred tragedy devote slain husband memory home salon official washington, Author: Matt Schudel\n",
            "Link: https://www.nytimes.com/2024/10/10/us/politics/ethel-kennedy-dead.html, Title: ethel kennedy passionate supporter family legacy die 96 remarry assassination husband senator robert f. kennedy devote work behalf cause champion, Author: Douglas Martin\n",
            "RSS feed fetched and written to CSV at 2024-10-10 16:41:47\n",
            "Link: https://abcnews.go.com/US/video/clearwater-fl-mayor-latest-concerns-amidst-hurricane-milton-114670000, Title: video clearwater fl mayor late concern amidst hurricane milton abc news linsey davis speak clearwater mayor bruce rector unpack big concern milton make landfall immediate step storm condition slow, Author: ABC News\n",
            "Link: https://www.cnn.com/2024/10/10/politics/ethel-kennedy-dies/index.html, Title: ethel kennedy human right activist widow robert f. kennedy die 96 ethel kennedy widow robert f. kennedy die family announce thursday 96, Author: Karl de Vries\n",
            "Link: https://www.miamiherald.com/news/local/environment/article293766234.html, Title: tornado major milton threat florida kill 4 destroy home nws miami send record number tornado warning ahead hurricane milton, Author: Alex Harris\n",
            "Link: https://www.washingtonpost.com/obituaries/2024/10/10/rfk-widow-ethel-kennedy-dies/, Title: ethel kennedy widow robert kennedy family matriarch die 96 scarred tragedy devote slain husband memory home salon official washington, Author: Matt Schudel\n",
            "Link: https://www.nytimes.com/2024/10/10/us/politics/ethel-kennedy-dead.html, Title: ethel kennedy passionate supporter family legacy die 96 remarry assassination husband senator robert f. kennedy devote work behalf cause champion, Author: Douglas Martin\n",
            "RSS feed fetched and written to CSV at 2024-10-10 16:42:00\n",
            "Link: https://abcnews.go.com/US/video/clearwater-fl-mayor-latest-concerns-amidst-hurricane-milton-114670000, Title: video clearwater fl mayor late concern amidst hurricane milton abc news linsey davis speak clearwater mayor bruce rector unpack big concern milton make landfall immediate step storm condition slow, Author: ABC News\n",
            "Link: https://www.cnn.com/2024/10/10/politics/ethel-kennedy-dies/index.html, Title: ethel kennedy human right activist widow robert f. kennedy die 96 ethel kennedy widow robert f. kennedy die family announce thursday 96, Author: Karl de Vries\n",
            "Link: https://www.miamiherald.com/news/local/environment/article293766234.html, Title: tornado major milton threat florida kill 4 destroy home nws miami send record number tornado warning ahead hurricane milton, Author: Alex Harris\n",
            "Link: https://www.washingtonpost.com/obituaries/2024/10/10/rfk-widow-ethel-kennedy-dies/, Title: ethel kennedy widow robert kennedy family matriarch die 96 scarred tragedy devote slain husband memory home salon official washington, Author: Matt Schudel\n",
            "Link: https://www.nytimes.com/2024/10/10/us/politics/ethel-kennedy-dead.html, Title: ethel kennedy passionate supporter family legacy die 96 remarry assassination husband senator robert f. kennedy devote work behalf cause champion, Author: Douglas Martin\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-3db72c09b9e4>\u001b[0m in \u001b[0;36m<cell line: 137>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import feedparser\n",
        "import pandas as pd\n",
        "import csv\n",
        "import schedule\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# RSS Feed URL\n",
        "RSS_URL = 'https://rss.app/feeds/atZtRJTsJwJI7KSQ.xml'\n",
        "\n",
        "# Function to fetch RSS data\n",
        "def fetch_rss():\n",
        "    try:\n",
        "        feed = feedparser.parse(RSS_URL)\n",
        "        if not feed.entries:\n",
        "            print(\"No entries found in the RSS feed.\")\n",
        "            return\n",
        "\n",
        "        with open('rss_feed.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "\n",
        "            # Write the header if the file is empty\n",
        "            if csvfile.tell() == 0:\n",
        "                writer.writerow(['Date', 'Title', 'Author', 'Summary', 'Category', 'Link'])\n",
        "\n",
        "            for entry in feed.entries:\n",
        "                date = entry.published.split('T')[0] if 'published' in entry else 'N/A'\n",
        "                title = entry.title if 'title' in entry else 'N/A'\n",
        "                author = entry.author if 'author' in entry else 'N/A'\n",
        "                summary = entry.summary if 'summary' in entry else 'N/A'\n",
        "                soup = BeautifulSoup(summary, 'html.parser')\n",
        "                summary_text = soup.get_text()\n",
        "\n",
        "                categories = ', '.join([cat.term for cat in entry.tags]) if 'tags' in entry else 'N/A'\n",
        "                link = entry.link if 'link' in entry else 'N/A'\n",
        "\n",
        "                writer.writerow([date, title, author, summary_text, categories, link])\n",
        "\n",
        "        print(f\"RSS feed fetched and written to CSV at {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while fetching the RSS feed: {e}\")\n",
        "\n",
        "# Function to process the RSS data\n",
        "def process_rss_data():\n",
        "    rss = pd.read_csv('rss_feed.csv')  # Load the most recent data\n",
        "    rss['Date'] = pd.to_datetime(rss['Date'], errors='coerce')\n",
        "\n",
        "    # Clean and preprocess the DataFrame\n",
        "    rss.dropna(subset=['Title'], inplace=True)\n",
        "    rss['Summary'] = rss['Summary'].astype(str)\n",
        "    rss['Text'] = rss['Summary'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())\n",
        "    rss.drop(['Summary'], axis=1, inplace=True)\n",
        "    rss.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Replace missing values\n",
        "    rss.fillna({\n",
        "        'Author': 'Unknown',\n",
        "        'Link': 'Not Found',\n",
        "        'Text': 'Text Not Found',\n",
        "        'Title': 'Title Not Found',\n",
        "        'Date': 'Date Not Found'\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Create a combined text column\n",
        "    rss['combined_text'] = rss['Title'] + ' ' + rss['Text']\n",
        "\n",
        "    # Process text for NLP\n",
        "    rss['combined_text'] = rss['combined_text'].apply(lambda x: preprocess_text(x))\n",
        "\n",
        "    return rss\n",
        "\n",
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text.lower())\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "\n",
        "# Function to convert text to vectors using TF-IDF\n",
        "def convert_to_vectors(df):\n",
        "    \"\"\"Converts the 'combined_text' column to TF-IDF vectors.\"\"\"\n",
        "    tfidf = TfidfVectorizer()\n",
        "    vectors = tfidf.fit_transform(df['combined_text'])\n",
        "    return vectors, tfidf\n",
        "\n",
        "# Function to perform Faiss search (placeholder)\n",
        "def faiss_search(vectors, query_vector, top_n=5):\n",
        "    \"\"\"Placeholder for Faiss search. Replace with actual Faiss implementation.\"\"\"\n",
        "    # This is a placeholder; you need to install Faiss and implement the search logic\n",
        "    # For now, it returns dummy results\n",
        "    D = np.array([[0.1, 0.2, 0.3, 0.4, 0.5]]) # Example distances\n",
        "    I = np.array([[0, 1, 2, 3, 4]])  # Example indices\n",
        "    return I, D\n",
        "\n",
        "# Function to recommend articles based on processed data\n",
        "def recommend_articles(df, query, top_n=5):\n",
        "    # Assuming a function to convert to vectors and normalize recency is defined\n",
        "    vectors, tfidf = convert_to_vectors(df)  # Implement this function as needed\n",
        "    query_vector = tfidf.transform([query]).toarray()\n",
        "\n",
        "    I, D = faiss_search(vectors, query_vector, top_n=top_n)  # Implement this function as needed\n",
        "\n",
        "    results = []\n",
        "    seen_titles = set()\n",
        "\n",
        "    for idx in I[0]:\n",
        "        row = df.iloc[idx]\n",
        "        final_score = 1 / (1 + D[0][I[0].tolist().index(idx)])  # Example scoring\n",
        "        title = row['combined_text']\n",
        "        if title not in seen_titles:\n",
        "            results.append((row['Link'], title, row['Author'], final_score))\n",
        "            seen_titles.add(title)\n",
        "\n",
        "    return sorted(results, key=lambda x: x[3], reverse=True)[:top_n]\n",
        "\n",
        "# Main function to automate the process\n",
        "def main():\n",
        "    fetch_rss()  # Fetch new data\n",
        "    processed_data = process_rss_data()  # Process the new data\n",
        "    results = recommend_articles(processed_data, query='your_query_here', top_n=5)  # Example query\n",
        "\n",
        "    # Print the results\n",
        "    for link, text, author, score in results:\n",
        "        print(f\"Link: {link}, Title: {text}, Author: {author}\")\n",
        "\n",
        "# Schedule the pipeline to run every 5 minutes\n",
        "schedule.every(5).minutes.do(main)\n",
        "\n",
        "# Run the scheduled task\n",
        "while True:\n",
        "    schedule.run_pending()\n",
        "    time.sleep(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-h0ts3IkSjL0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}